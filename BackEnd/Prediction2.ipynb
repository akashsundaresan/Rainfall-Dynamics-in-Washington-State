{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'file_path.csv' with the path to your CSV file\n",
    "df = pd.read_csv('../Data/csv/WashingtonWeather.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[['Unnamed: 0', 'WBAN', 'LBL', 'YEARMODA', 'DAY', 'CTRY', 'STATE', 'LAT', 'LON']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data before and after 2019 for train and test sets\n",
    "train_data = df[df['YEAR'] < 2019]\n",
    "test_data = df[df['YEAR'] >= 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using PCA\n",
    "target_train = train_data['PRCP']\n",
    "features_train = train_data.drop(['PRCP'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)  # You can change the number of components\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "principal_df = pd.DataFrame(data=principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the principal components with the target variable for train data\n",
    "final_train_df = pd.concat([principal_df, target_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(final_train_df.drop(['PRCP'], axis=1), final_train_df['PRCP'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_val = np.reshape(X_val.values, (X_val.shape[0], 1, X_val.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "target_test = test_data['PRCP']\n",
    "features_test = test_data.drop(['PRCP'], axis=1)\n",
    "scaled_features_test = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test = PCA(n_components=5)  # Same number of components as trained PCA\n",
    "principal_components_test = pca_test.fit_transform(scaled_features_test)\n",
    "principal_df_test = pd.DataFrame(data=principal_components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the principal components with the target variable for test data\n",
    "final_test_df = pd.concat([principal_df_test, target_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data for LSTM\n",
    "y_test = final_test_df['PRCP']\n",
    "final_test_df = final_test_df.drop(['PRCP'], axis=1)\n",
    "X_test = np.reshape(final_test_df.values, (final_test_df.shape[0], 1, final_test_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "predicted_values = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics\n",
    "mse = mean_squared_error(y_test, predicted_values)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for training\n",
    "columns_to_use = ['USAF', 'YEAR', 'MONTH', 'TEMP', 'DEWP', 'WDSP', 'MAX', 'MIN', 'PRCP']\n",
    "train_data = df[columns_to_use]\n",
    "\n",
    "# Filter data for training (before 2019)\n",
    "train_data = train_data[train_data['YEAR'] < 2019]\n",
    "\n",
    "# Splitting data into features (X) and target (y)\n",
    "X = train_data.drop('PRCP', axis=1)  # Features\n",
    "y = train_data['PRCP']  # Target\n",
    "\n",
    "# Normalizing data using Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the dataset into training and testing sets (using 2019 data for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable\n",
    "target = train_data['PRCP']\n",
    "features = train_data.drop(['PRCP'], axis=1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=5)  # Specify the number of components you want to keep\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "\n",
    "# Create a dataframe with the principal components\n",
    "principal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "\n",
    "# Concatenate the principal components with the target variable\n",
    "final_df = pd.concat([principal_df, target], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
